{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <font style=\"color:rgb(100,109,254)\">  Smart Background Subtraction  </font> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in many cases you don't have a clear background image, an example of this is maybe a highway which is always busy, or a maybe walking destination which is always crowded. So in those cases you subtract the background by other means, for e.g you detect movement, so those objects which move can be foreground and those that remain static is part of background.\n",
    "\n",
    "Now there also shadows of objects which also move and there are other as well, so several algorithms have been invented for this purpose. OpenCV has implemented a few such algorithms which are very easy to use. lets see them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(134,19,348)\"> BackgroundSubtractorMOG </font>\n",
    "\n",
    "It is a Gaussian Mixture-based Background/Foreground Segmentation Algorithm. It was introduced in the paper *\"An improved adaptive background mixture model for real-time tracking with shadow detection\"* by **P. KadewTraKuPong** and **R. Bowden** in 2001. \n",
    "\n",
    "First we need to create the background subtractor object with `cv2.bgsegm.createBackgroundSubtractorMOG()`. Then inside the loop in which you show frames of video you use `backgroundsubtractor.apply()` method to get the foreground mask.\n",
    "\n",
    "[```retval\t=\tcv.bgsegm.createBackgroundSubtractorMOG([, history[, nmixtures[, backgroundRatio[, noiseSigma]]]])```](https://docs.opencv.org/4.2.0/d2/d55/group__bgsegm.html#ga17d9525d2ad71f74d8d29c2c5e11903d)\n",
    "\n",
    "- `history`\tLength of the history.\n",
    "- `nmixtures`\tNumber of Gaussian mixtures.\n",
    "- `backgroundRatio`\tBackground ratio.\n",
    "- `noiseSigma\t`Noise strength (standard deviation of the brightness or each color channel). 0 means some automatic value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a video\n",
    "cap = cv2.VideoCapture('media/M4/vtest.avi')\n",
    "\n",
    "# you can optionally work on the live web cam\n",
    "#cap = cv.VideoCapture(1)\n",
    "\n",
    "# create the background object\n",
    "backgroundobject = cv2.bgsegm.createBackgroundSubtractorMOG(backgroundRatio=0.1)\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()  \n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    # apply the background object on each frame\n",
    "    fgmask = backgroundobject.apply(frame)\n",
    "\n",
    "    # also extracting the real detected foreground part of the image (optional)\n",
    "    real_part = cv2.bitwise_and(frame,frame,mask=fgmask)\n",
    "    \n",
    "    # making fgmask 3 channeled so it can be stacked with others\n",
    "    fgmask_3 = cv2.cvtColor(fgmask, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Stack all three frames and show the image\n",
    "    stacked = np.hstack((fgmask_3,frame,real_part))\n",
    "    cv2.imshow('All three',cv2.resize(stacked,None,fx=0.65,fy=0.65))\n",
    " \n",
    "    k = cv2.waitKey(30) &  0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "   \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(134,19,348)\"> BackgroundSubtractorMOG2 </font>\n",
    "It is also a Gaussian Mixture-based Background/Foreground Segmentation Algorithm. It is based on two papers by **Z.Zivkovic**, *\"Improved adaptive Gaussian mixture model for background subtraction\"* in 2004 and *\"Efficient Adaptive Density Estimation per Image Pixel for the Task of Background Subtraction\"* in 2006. One important feature of this algorithm is that it selects the appropriate number of Gaussian distribution for each pixel. (Remember, in last case, we took a K Gaussian distributions throughout the algorithm). This provides better adaptability to varying scenes due illumination changes etc.\n",
    "\n",
    "As in previous case, we have to create a background subtractor object. Here, you have an option of detecting shadows or not. If detectShadows = True (which is so by default), it detects and marks shadows, but decreases the speed. Shadows will be marked in gray color.\n",
    "\n",
    "[```retval\t=\tcv2.createBackgroundSubtractorMOG2(\t[, history[, varThreshold[, detectShadows]]]\t)```](https://docs.opencv.org/4.2.0/de/de1/group__video__motion.html#ga2beb2dee7a073809ccec60f145b6b29c)\n",
    "\n",
    "- `history`\tLength of the history.\n",
    "- `varThreshold`\tThreshold on the squared distance between the pixel and the model to decide whether a pixel is well described by the background model. This parameter does not affect the background update.\n",
    "- `detectShadows`\tIf true, the algorithm will detect shadows and mark them. It decreases the speed a bit, so if you do not need this feature, set the parameter to false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a video\n",
    "cap = cv2.VideoCapture('media/M4/vtest.avi')\n",
    "\n",
    "# you can optionally work on the live web cam\n",
    "#cap = cv.VideoCapture(1)\n",
    "\n",
    "# create the background object, you can choose to detect shadows or not (if True they will be shown as gray)\n",
    "backgroundobject = cv2.createBackgroundSubtractorMOG2( detectShadows = True )\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()  \n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    # apply the background object on each frame\n",
    "    fgmask = backgroundobject.apply(frame)\n",
    "\n",
    "    # also extracting the real detected foreground part of the image (optional)\n",
    "    real_part = cv2.bitwise_and(frame,frame,mask=fgmask)\n",
    "    \n",
    "    # making fgmask 3 channeled so it can be stacked with others\n",
    "    fgmask_3 = cv2.cvtColor(fgmask, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Stack all three frames and show the image\n",
    "    stacked = np.hstack((fgmask_3,frame,real_part))\n",
    "    cv2.imshow('All three',cv2.resize(stacked,None,fx=0.65,fy=0.65))\n",
    " \n",
    "    k = cv2.waitKey(30) &  0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "   \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(134,19,348)\"> Another Background Subtractor  </font>\n",
    "\n",
    "This is a implementation of the different yet better algorithm which is called GSOC, as it was implemented during GSOC and was not originated from any paper.\n",
    "\n",
    "\n",
    "[```retval=cv2.bgsegm.createBackgroundSubtractorGSOC(\t[, mc[, nSamples[, replaceRate[, propagationRate[, hitsThreshold[, alpha[, beta[, blinkingSupressionDecay[, blinkingSupressionMultiplier[, noiseRemovalThresholdFacBG[, noiseRemovalThresholdFacFG]]]]]]]]]]]\t)```](https://docs.opencv.org/4.2.0/d2/d55/group__bgsegm.html#ga7ba3e826c343adc15782ab9139f82445)\n",
    "\n",
    "\n",
    "- `mc`\tWhether to use camera motion compensation.\n",
    "- `nSamples`\tNumber of samples to maintain at each point of the frame.\n",
    "- `replaceRate`\tProbability of replacing the old sample - how fast the model will update itself.\n",
    "- `propagationRate`\tProbability of propagating to neighbors.\n",
    "- `hitsThreshold`\tHow many positives the sample must get before it will be considered as a possible replacement.\n",
    "- `alpha`\tScale coefficient for threshold.\n",
    "- `beta`\tBias coefficient for threshold.\n",
    "- `blinkingSupressionDecay`\tBlinking suppression decay factor.\n",
    "- `blinkingSupressionMultiplier`\tBlinking suppression multiplier.\n",
    "- `noiseRemovalThresholdFacBG`\tStrength of the noise removal for background points.\n",
    "- `noiseRemovalThresholdFacFG`\tStrength of the noise removal for foreground points.\n",
    "\n",
    "**All backgroundsubtractors above also accept below params in the apply function**\n",
    "\n",
    "> fgmask\t=\tcv2.bgsegm_BackgroundSubtractorGSOC.apply(\timage[, fgmask[, learningRate]]\t)\n",
    "\n",
    "- `image`\tNext video frame.\n",
    "- `fgmask`\tThe output foreground mask as an 8-bit binary image.\n",
    "- `learningRate`\tThe value between 0 and 1 that indicates how fast the background model is learned. Negative parameter value makes the algorithm to use some automatically chosen learning rate. 0 means that the background model is not updated at all, 1 means that the background model is completely reinitialized from the last frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a video\n",
    "cap = cv2.VideoCapture('media/M4/vtest.avi')\n",
    "\n",
    "# you can optionally work on the live web cam\n",
    "#cap = cv.VideoCapture(1)\n",
    "\n",
    "# create the background object\n",
    "backgroundobject = cv2.bgsegm.createBackgroundSubtractorGSOC()\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()  \n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    # apply the background object on each frame\n",
    "    fgmask = backgroundobject.apply(frame)\n",
    "\n",
    "    # also extracting the real detected foreground part of the image (optional)\n",
    "    real_part = cv2.bitwise_and(frame,frame,mask=fgmask)\n",
    "    \n",
    "    # making fgmask 3 channeled so it can be stacked with others\n",
    "    fgmask_3 = cv2.cvtColor(fgmask, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Stack all three frames and show the image\n",
    "    stacked = np.hstack((fgmask_3,frame,real_part))\n",
    "    cv2.imshow('All three',cv2.resize(stacked,None,fx=0.65,fy=0.65))\n",
    " \n",
    "    k = cv2.waitKey(3) &  0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "   \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are about 5 more Algorithms in opencv on background subtraction which you can look at here along with their params**\n",
    "https://docs.opencv.org/4.1.0/d2/d55/group__bgsegm.html   <br>\n",
    "https://docs.opencv.org/4.1.0/de/de1/group__video__motion.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
